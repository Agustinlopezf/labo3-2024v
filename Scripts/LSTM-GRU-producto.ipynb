{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>...</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>mes</th>\n",
       "      <th>quarter</th>\n",
       "      <th>fin_quarter</th>\n",
       "      <th>edad_producto</th>\n",
       "      <th>ventas_cat1</th>\n",
       "      <th>ventas_cat2</th>\n",
       "      <th>ventas_cat3</th>\n",
       "      <th>ventas_familia_producto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.31686</td>\n",
       "      <td>4.96628</td>\n",
       "      <td>3.03194</td>\n",
       "      <td>0.25684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.14290</td>\n",
       "      <td>0.10339</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.59237</td>\n",
       "      <td>2.23835</td>\n",
       "      <td>1.52777</td>\n",
       "      <td>0.04699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.18260</td>\n",
       "      <td>4.47157</td>\n",
       "      <td>2.35257</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.79714</td>\n",
       "      <td>0.50130</td>\n",
       "      <td>0.09348</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  customer_id  product_id  plan_precios_cuidados   \n",
       "0  2017-01-01        10234       20524                    0.0  \\\n",
       "1  2017-02-01        10234       20524                    NaN   \n",
       "2  2017-03-01        10234       20524                    0.0   \n",
       "3  2017-04-01        10234       20524                    NaN   \n",
       "4  2017-05-01        10234       20524                    NaN   \n",
       "\n",
       "   cust_request_qty  cust_request_tn       tn cat1     cat2        cat3  ...   \n",
       "0               2.0          0.05300  0.05300   HC  VAJILLA  Cristalino  ...  \\\n",
       "1               0.0          0.00000  0.00000   HC  VAJILLA  Cristalino  ...   \n",
       "2               1.0          0.01514  0.01514   HC  VAJILLA  Cristalino  ...   \n",
       "3               0.0          0.00000  0.00000   HC  VAJILLA  Cristalino  ...   \n",
       "4               0.0          0.00000  0.00000   HC  VAJILLA  Cristalino  ...   \n",
       "\n",
       "  sku_size    descripcion mes  quarter  fin_quarter  edad_producto   \n",
       "0    500.0  Abrillantador   1        1            0              0  \\\n",
       "1    500.0  Abrillantador   2        1            0              1   \n",
       "2    500.0  Abrillantador   3        1            1              2   \n",
       "3    500.0  Abrillantador   4        2            0              3   \n",
       "4    500.0  Abrillantador   5        2            0              4   \n",
       "\n",
       "   ventas_cat1  ventas_cat2  ventas_cat3  ventas_familia_producto  \n",
       "0     14.31686      4.96628      3.03194                  0.25684  \n",
       "1      2.14290      0.10339      0.00000                  0.00000  \n",
       "2      8.59237      2.23835      1.52777                  0.04699  \n",
       "3      9.18260      4.47157      2.35257                  0.00000  \n",
       "4      7.79714      0.50130      0.09348                  0.00000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entorno = 'local'  # Elegir \"VM\" o \"local\" para correr en entorno local\n",
    "nombre_experimento = 'LSTM-GRU_producto'\n",
    "#nombre_carpeta_optuna = 'LSTM-GRU_producto'\n",
    "ventana_input = 12\n",
    "ventana_output = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configurar entorno\n",
    "if entorno == 'VM':\n",
    "    carpeta_datasets = os.path.expanduser('~/buckets/b1/datasets')\n",
    "    carpeta_exp_base = os.path.expanduser('~/buckets/b1/exp')\n",
    "elif entorno == 'local':\n",
    "    carpeta_datasets = 'C:\\\\Users\\\\alope\\\\Desktop\\\\Trámites\\\\Maestria Data Science - Universidad Austral\\\\Laboratorio de implementación 3\\\\Datos'\n",
    "    carpeta_exp_base = 'C:\\\\Users\\\\alope\\\\Desktop\\\\Trámites\\\\Maestria Data Science - Universidad Austral\\\\Laboratorio de implementación 3\\\\Resultados'\n",
    "else:\n",
    "    raise Exception(\"Entorno especificado incorrectamente\")\n",
    "\n",
    "carpeta_exp = os.path.join(carpeta_exp_base, nombre_experimento)\n",
    "if not os.path.exists(carpeta_exp):\n",
    "    os.makedirs(carpeta_exp)\n",
    "\n",
    "\n",
    "dataset_completo = pd.read_csv(os.path.join(carpeta_datasets, 'df_producto_cliente_completo.csv'))\n",
    "\n",
    "\n",
    "dataset_completo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>product_id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>20001</td>\n",
       "      <td>934.77222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>20002</td>\n",
       "      <td>550.15707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>20003</td>\n",
       "      <td>1063.45835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>20004</td>\n",
       "      <td>555.91614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>20005</td>\n",
       "      <td>494.27011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>21263</td>\n",
       "      <td>0.01270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>21265</td>\n",
       "      <td>0.05007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>21266</td>\n",
       "      <td>0.05121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22373</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>21267</td>\n",
       "      <td>0.01569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22374</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>21276</td>\n",
       "      <td>0.00892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ds  product_id           y\n",
       "0      2017-01-01       20001   934.77222\n",
       "1      2017-01-01       20002   550.15707\n",
       "2      2017-01-01       20003  1063.45835\n",
       "3      2017-01-01       20004   555.91614\n",
       "4      2017-01-01       20005   494.27011\n",
       "...           ...         ...         ...\n",
       "22370  2019-12-01       21263     0.01270\n",
       "22371  2019-12-01       21265     0.05007\n",
       "22372  2019-12-01       21266     0.05121\n",
       "22373  2019-12-01       21267     0.01569\n",
       "22374  2019-12-01       21276     0.00892\n",
       "\n",
       "[22375 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventas_producto_mes = dataset_completo.groupby(['Timestamp', 'product_id'])['tn'].sum().reset_index()\n",
    "ventas_producto_mes = ventas_producto_mes.rename(columns={'tn': 'y', 'Timestamp': 'ds'})\n",
    "ventas_producto_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing product_id: 20001\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction for product 20001: 1464.2740970017128\n",
      "Analyzing product_id: 20002\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction for product 20002: 1043.10414579687\n",
      "Analyzing product_id: 20003\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction for product 20003: 1021.4891134540533\n",
      "Analyzing product_id: 20004\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction for product 20004: 665.8367518203794\n",
      "Analyzing product_id: 20005\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction for product 20005: 558.741504975904\n",
      "Analyzing product_id: 20006\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction for product 20006: 484.8531843054999\n",
      "Analyzing product_id: 20007\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction for product 20007: 318.9263959667412\n",
      "Analyzing product_id: 20008\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction for product 20008: 502.83087910767557\n",
      "Analyzing product_id: 20009\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction for product 20009: 515.6395416532278\n",
      "Analyzing product_id: 20010\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction for product 20010: 428.68023642165974\n",
      "Analyzing product_id: 20011\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction for product 20011: 395.17744405361236\n",
      "Analyzing product_id: 20012\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction for product 20012: 331.5310150131469\n",
      "Analyzing product_id: 20013\n",
      "X shape: (25, 6, 10), y shape: (25,)\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction for product 20013: 423.3945636027815\n",
      "\n",
      "Summary of predictions:\n",
      "Product 20001: 1464.2740970017128\n",
      "Product 20002: 1043.10414579687\n",
      "Product 20003: 1021.4891134540533\n",
      "Product 20004: 665.8367518203794\n",
      "Product 20005: 558.741504975904\n",
      "Product 20006: 484.8531843054999\n",
      "Product 20007: 318.9263959667412\n",
      "Product 20008: 502.83087910767557\n",
      "Product 20009: 515.6395416532278\n",
      "Product 20010: 428.68023642165974\n",
      "Product 20011: 395.17744405361236\n",
      "Product 20012: 331.5310150131469\n",
      "Product 20013: 423.3945636027815\n",
      "\n",
      "Total products analyzed: 13\n",
      "Products with valid predictions: 13\n",
      "Products without predictions: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, GRU, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# Enable TensorFlow debug mode for better error tracking\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "# Filter keras UserWarnings to reduce output noise\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='keras')\n",
    "\n",
    "# Function to create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Function to add additional features to the data\n",
    "def add_features(data):\n",
    "    df = pd.DataFrame(data, columns=['y'])\n",
    "    df['lag_1'] = df['y'].shift(1)\n",
    "    df['lag_2'] = df['y'].shift(2)\n",
    "    df['ma_3'] = df['y'].rolling(window=3).mean()\n",
    "    df['ma_6'] = df['y'].rolling(window=6).mean()\n",
    "    df['std_3'] = df['y'].rolling(window=3).std()\n",
    "    df['trend'] = range(len(df))\n",
    "    df['month'] = df.index % 12 + 1\n",
    "    df['sin_month'] = np.sin(2 * np.pi * df['month']/12)\n",
    "    df['cos_month'] = np.cos(2 * np.pi * df['month']/12)\n",
    "    df.dropna(inplace=True)\n",
    "    return df.values\n",
    "\n",
    "# Custom loss function combining MSE and MAE\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse = K.mean(K.square(y_true - y_pred))\n",
    "    mae = K.mean(K.abs(y_true - y_pred))\n",
    "    return 0.5 * mse + 0.5 * mae\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True, input_shape=input_shape)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        GRU(32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss)\n",
    "    return model\n",
    "\n",
    "# Main execution script\n",
    "if __name__ == \"__main__\":\n",
    "    seq_length = 6\n",
    "    product_ids_lstm = list(range(20001, 20014))\n",
    "    lista_productos_lstm = []\n",
    "    lista_predicciones_mes2_lstm = []\n",
    "\n",
    "    for producto in product_ids_lstm:\n",
    "        print(f\"Analyzing product_id: {producto}\")\n",
    "\n",
    "        # Assuming 'ventas_producto_mes' is your sales data\n",
    "        ventas_mes_por_producto = ventas_producto_mes[ventas_producto_mes['product_id'] == producto].copy()\n",
    "\n",
    "        # Sorting by date if 'date' column exists, otherwise by index\n",
    "        if 'date' in ventas_mes_por_producto.columns:\n",
    "            ventas_mes_por_producto['date'] = pd.to_datetime(ventas_mes_por_producto['date'])\n",
    "            ventas_mes_por_producto = ventas_mes_por_producto.sort_values('date')\n",
    "        else:\n",
    "            ventas_mes_por_producto = ventas_mes_por_producto.sort_index()\n",
    "\n",
    "        data = ventas_mes_por_producto[['y']].values\n",
    "\n",
    "        if len(data) < seq_length + 2:\n",
    "            print(f\"Insufficient data for product {producto}. Using mean prediction.\")\n",
    "            mean_prediction = np.mean(data)\n",
    "            lista_productos_lstm.append(producto)\n",
    "            lista_predicciones_mes2_lstm.append(mean_prediction)\n",
    "            continue\n",
    "\n",
    "        data = np.log1p(data)\n",
    "\n",
    "        data_with_features = add_features(data)\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        data_scaled = scaler.fit_transform(data_with_features)\n",
    "\n",
    "        X, y = create_sequences(data_scaled, seq_length)\n",
    "\n",
    "        print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "        if len(X) < 10:\n",
    "            print(f\"Insufficient data for product {producto} after sequence creation. Using mean prediction.\")\n",
    "            mean_prediction = np.mean(np.expm1(data))\n",
    "            lista_productos_lstm.append(producto)\n",
    "            lista_predicciones_mes2_lstm.append(mean_prediction)\n",
    "            continue\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "        predictions = []\n",
    "\n",
    "        for train_index, test_index in tscv.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model = build_model((seq_length, data_with_features.shape[1]))\n",
    "\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "            model.fit(X_train, y_train, \n",
    "                      epochs=300,\n",
    "                      batch_size=32,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stop, reduce_lr], \n",
    "                      verbose=0)\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.extend(pred.flatten())\n",
    "\n",
    "        try:\n",
    "            last_sequence = data_scaled[-seq_length:]\n",
    "            last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "\n",
    "            next_month_prediction = model.predict(last_sequence)\n",
    "            next_month_prediction = scaler.inverse_transform(np.hstack([next_month_prediction, np.zeros((next_month_prediction.shape[0], data_with_features.shape[1]-1))]))[0][0]\n",
    "            next_month_prediction = np.expm1(next_month_prediction)\n",
    "\n",
    "            next_month_prediction_scaled = scaler.transform(np.hstack([np.array([[np.log1p(next_month_prediction)]]), np.zeros((1, data_with_features.shape[1]-1))]))\n",
    "            last_sequence = np.concatenate([last_sequence[:, 1:, :], np.expand_dims(next_month_prediction_scaled, axis=1)], axis=1)\n",
    "            next_2_month_prediction = model.predict(last_sequence)\n",
    "            next_2_month_prediction = scaler.inverse_transform(np.hstack([next_2_month_prediction, np.zeros((next_2_month_prediction.shape[0], data_with_features.shape[1]-1))]))[0][0]\n",
    "            next_2_month_prediction = np.expm1(next_2_month_prediction)\n",
    "\n",
    "            # Ensemble with historical average\n",
    "            historical_avg = np.mean(np.expm1(data[-12:]))  # Average of last 12 months\n",
    "            final_prediction = 0.7 * next_2_month_prediction + 0.3 * historical_avg\n",
    "\n",
    "            lista_productos_lstm.append(producto)\n",
    "            lista_predicciones_mes2_lstm.append(final_prediction)\n",
    "            print(f\"Prediction for product {producto}: {final_prediction}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during final prediction for product {producto}: {str(e)}\")\n",
    "            lista_productos_lstm.append(producto)\n",
    "            lista_predicciones_mes2_lstm.append(np.nan)\n",
    "\n",
    "    # Creating results DataFrame and saving predictions to CSV\n",
    "    resultados_kaggle_lstm = pd.DataFrame({'product_id': lista_productos_lstm, 'tn': lista_predicciones_mes2_lstm})\n",
    "    directorio_script = '.'  # Change this to your desired directory\n",
    "    resultados_kaggle_lstm.to_csv(os.path.join(directorio_script, 'predicciones_lstm_improved8_extended.csv'), index=False)\n",
    "\n",
    "    # Printing summary of predictions\n",
    "    print(\"\\nSummary of predictions:\")\n",
    "    for producto, prediccion in zip(lista_productos_lstm, lista_predicciones_mes2_lstm):\n",
    "        print(f\"Product {producto}: {prediccion}\")\n",
    "\n",
    "    # Printing total products analyzed and counts of valid vs. missing predictions\n",
    "    print(f\"\\nTotal products analyzed: {len(lista_productos_lstm)}\")\n",
    "    print(f\"Products with valid predictions: {sum(~np.isnan(lista_predicciones_mes2_lstm))}\")\n",
    "    print(f\"Products without predictions: {sum(np.isnan(lista_predicciones_mes2_lstm))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.0936\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0525\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0472\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 0.0476\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0481\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0493\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.0574\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0602\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0456\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0457\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0450\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0459\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0444\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0500\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0456\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0458\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0447\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0462\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.0470\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0472\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.1083\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0846\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0887\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0774\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.0837\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0858\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 1s 70ms/step - loss: 0.0730\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 1s 66ms/step - loss: 0.0796\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 1s 57ms/step - loss: 0.0796\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0727\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 1s 63ms/step - loss: 0.0832\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0733\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.0726\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0752\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 1s 56ms/step - loss: 0.0699\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 1s 68ms/step - loss: 0.0772\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0715\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0714\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0715\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.0794\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 1s 69ms/step - loss: 0.0637\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 1s 66ms/step - loss: 0.0503\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0732\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0651\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0485\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 1s 67ms/step - loss: 0.0540\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 1s 66ms/step - loss: 0.0399\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 1s 66ms/step - loss: 0.0405\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0415\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0423\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 1s 65ms/step - loss: 0.0400\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0364\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0391\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0335\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0423\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0399\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0455\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 1s 58ms/step - loss: 0.0357\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0306\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 0.0349\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0600\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 1s 62ms/step - loss: 0.0385\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0390\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 1s 60ms/step - loss: 0.0363\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 0.0423\n",
      "Epoch 6/20\n",
      " 4/19 [=====>........................] - ETA: 0s - loss: 0.0179  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     75\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1284\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1265\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1268\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1270\u001b[0m     outputs,\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1272\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1273\u001b[0m )\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1312\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1315\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1316\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1050\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m-> 1050\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1051\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:558\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    556\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1144\u001b[0m ):\n\u001b[1;32m-> 1145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\sequential.py:412\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m outputs \u001b[38;5;241m=\u001b[39m inputs  \u001b[38;5;66;03m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;66;03m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;66;03m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;66;03m# the next layer.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\functional.py:512\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\functional.py:669\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 669\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    673\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[0;32m    674\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1144\u001b[0m ):\n\u001b[1;32m-> 1145\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\layers\\core\\dense.py:252\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mset_shape(output_shape)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3554\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3551\u001b[0m   value \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3552\u001b[0m   bias \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(bias, dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:901\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    900\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBiasAdd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    904\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PROMEDIO PARA RESTO\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 12  # Use last 12 months to predict next month\n",
    "\n",
    "lista_productos_lstm = []\n",
    "lista_predicciones_mes2_lstm = []\n",
    "\n",
    "# Define the range of product_ids to skip\n",
    "skip_product_ids = list(range(20001, 20014))\n",
    "\n",
    "for producto in ventas_producto_mes['product_id'].unique():\n",
    "    if producto in skip_product_ids:\n",
    "        continue\n",
    "    \n",
    "    if producto in productos_predecir['product_id'].values:\n",
    "        ventas_mes_por_producto = ventas_producto_mes[ventas_producto_mes['product_id'] == producto].copy()\n",
    "        data = ventas_mes_por_producto['y'].values.reshape(-1, 1)\n",
    "\n",
    "        # If not enough data, use mean as prediction\n",
    "        if len(data) < seq_length + 1:\n",
    "            mean_prediction = np.mean(data)\n",
    "            print(f\"Not enough data for product {producto}, using mean prediction: {mean_prediction}\")\n",
    "            lista_productos_lstm.append(producto)\n",
    "            lista_predicciones_mes2_lstm.append(mean_prediction)\n",
    "            continue\n",
    "\n",
    "        # Scale data\n",
    "        scaler = MinMaxScaler()\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "        # Create sequences\n",
    "        X, y = create_sequences(data_scaled, seq_length)\n",
    "\n",
    "        # Check if there are enough data points\n",
    "        if len(X) == 0:\n",
    "            mean_prediction = np.mean(data)\n",
    "            print(f\"Not enough data for product {producto}, using mean prediction: {mean_prediction}\")\n",
    "            lista_productos_lstm.append(producto)\n",
    "            lista_predicciones_mes2_lstm.append(mean_prediction)\n",
    "            continue\n",
    "\n",
    "        # Split into train and test sets\n",
    "        split = int(len(X) * 0.8)\n",
    "        X_train, y_train = X[:split], y[:split]\n",
    "        X_test, y_test = X[split:], y[split:]\n",
    "\n",
    "        # Define LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=1)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = scaler.inverse_transform(predictions)\n",
    "        y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Predict next 2 months\n",
    "        last_sequence = data_scaled[-seq_length:]\n",
    "        last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "        next_month_prediction = model.predict(last_sequence)\n",
    "        next_month_prediction = scaler.inverse_transform(next_month_prediction)[0][0]\n",
    "\n",
    "        # Prepare last sequence for the next prediction\n",
    "        next_month_prediction_scaled = scaler.transform(np.array([[next_month_prediction]]))\n",
    "        last_sequence = np.append(last_sequence[:, 1:, :], np.expand_dims(next_month_prediction_scaled, axis=0), axis=1)\n",
    "        next_2_month_prediction = model.predict(last_sequence)\n",
    "        next_2_month_prediction = scaler.inverse_transform(next_2_month_prediction)[0][0]\n",
    "\n",
    "        lista_productos_lstm.append(producto)\n",
    "        lista_predicciones_mes2_lstm.append(next_2_month_prediction)\n",
    "\n",
    "# Save results\n",
    "resultados_kaggle_lstm = pd.DataFrame({'product_id': lista_productos_lstm, 'tn': lista_predicciones_mes2_lstm})\n",
    "resultados_kaggle_lstm.to_csv(os.path.join(directorio_script, 'predicciones_lstm64.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los archivos CSV\n",
    "file1 = 'predicciones_lstm_improved8_extended.csv'\n",
    "file2 = 'predicciones_lstm64.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Concatenar los DataFrames\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame fusionado en un nuevo archivo CSV\n",
    "output_file = 'predicciones_lstm_fusionadas.csv'\n",
    "df_concat.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Se han fusionado y guardado las predicciones en {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
